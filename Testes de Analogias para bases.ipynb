{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel(modelFile):\n",
    "    model = KeyedVectors.load_word2vec_format(modelFile)\n",
    "    return model\n",
    "\n",
    "# https://datascience-enthusiast.com/DL/Operations_on_word_vectors.html\n",
    "def similar_cos(u, v):\n",
    "    distance = 0.0\n",
    "\n",
    "    # Compute the dot product between u and v (≈1 line)\n",
    "    dot = np.dot(u, v)\n",
    "    # Compute the L2 norm of u (≈1 line)\n",
    "#     norm_u = np.sqrt(np.sum(u**2))\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    \n",
    "    # Compute the L2 norm of v (≈1 line)\n",
    "#     norm_v = np.sqrt(np.sum(v**2))\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    \n",
    "    # Compute the cosine similarity defined by formula (1) (≈1 line)\n",
    "    cosine_similarity = dot / (norm_u * norm_v)\n",
    "\n",
    "    return cosine_similarity\n",
    "\n",
    "def extract_relation(target, related):\n",
    "    return target - related\n",
    "\n",
    "def find_best_related_word(target, relation, model):\n",
    "#     related = target + relation\n",
    "    max_sim = 0.0\n",
    "    best_word = None\n",
    "    for word in model.vocab:\n",
    "        relation1 = relation.reshape(1,-1)\n",
    "        relation2 = extract_relation(model.word_vec(target), model.word_vec(word)).reshape(1,-1)\n",
    "        sim = cosine_similarity(relation1, relation2)\n",
    "        if(sim > max_sim):\n",
    "            best_word = word\n",
    "    \n",
    "    return best_word;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processTriadAnalogy(word1,word2,word3, modelsList):\n",
    "    result = []\n",
    "    for modelFileRef in modelsList:\n",
    "        model = getModel(modelFileRef)\n",
    "        v_word1 = model.word_vec(word1)\n",
    "        v_word2 = model.word_vec(word2)\n",
    "        basisRelation = extract_relation(v_word1, v_word2)\n",
    "        if(word1 in model and word2 in model and word3 in model):\n",
    "            bestWordOnModel = find_best_related_word(word3, basisRelation, model)\n",
    "            result.append('Model: ' + modelFileRef + '/n Best Word : ' + bestWordOnModel)\n",
    "        else:\n",
    "            print('Fail:Word not found in model')\n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = processTriadAnalogy(word1,word2,word3,modelsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Teste 1 - Biblioteca KeyedVector e seus metodos de similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsList = glob('../models/*.txt')\n",
    "word1 = 'rei'\n",
    "word2 = 'homem'\n",
    "word3 = 'rainha'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel(modelsList[2])\n",
    "\n",
    "list = model.most_similar(positive=[word1,word3], negative=[word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/cbow_s100.txt [('raínha', 0.6748343706130981), ('princesa', 0.6687842607498169), ('rainha-consorte', 0.6617846488952637), ('rainha-mãe', 0.6472653746604919), ('duquesa', 0.6418556571006775), ('pártia', 0.6328529119491577), ('imperatriz', 0.628162682056427), ('primogénita', 0.6190635561943054), ('condessa', 0.6179429292678833), ('coroação', 0.6084483861923218)]\n",
      "Positive:   rei rainha \n",
      "Negative: homem\n"
     ]
    }
   ],
   "source": [
    "print(modelsList[2], list)\n",
    "print('Positive:  ', word1,word3, '\\nNegative:',word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Troca de Palavras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = 'rei'\n",
    "word2 = 'homem'\n",
    "word3 = 'mulher'\n",
    "\n",
    "model = getModel(modelsList[2])\n",
    "\n",
    "list = model.most_similar(positive=[word1,word3], negative=[word2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/cbow_s100.txt [('esposa', 0.688875675201416), ('filha', 0.6741011142730713), ('governanta', 0.6724554896354675), ('sobrinha', 0.669994056224823), ('madrasta', 0.6670832633972168), ('concubina', 0.6659663915634155), ('dama-de-companhia', 0.6614803075790405), ('benção', 0.659320056438446), ('múmia', 0.6535747051239014), ('bênção', 0.6500141620635986)]\n",
      "Positive:   rei mulher \n",
      "Negative: homem\n"
     ]
    }
   ],
   "source": [
    "print(modelsList[2], list)\n",
    "print('Positive:  ', word1,word3, '\\nNegative:',word2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
